"""
Script ƒë·ªÉ generate c√°c notebook chu·∫©n h√≥a t·ª´ template.
Ch·∫°y script n√†y ƒë·ªÉ t·∫°o c√°c notebook theo layout chu·∫©n.
"""

import json
import os

def create_notebook_cell(cell_type, source, metadata=None):
    """T·∫°o m·ªôt notebook cell."""
    cell = {
        "cell_type": cell_type,
        "metadata": metadata or {},
        "source": source if isinstance(source, list) else [source]
    }
    if cell_type == "code":
        cell["execution_count"] = None
        cell["outputs"] = []
    return cell

def create_late_delivery_notebook():
    """T·∫°o notebook cho Late Delivery Prediction."""
    cells = [
        # Header
        create_notebook_cell("markdown", """# M√î H√åNH: D·ª∞ ƒêO√ÅN GIAO H√ÄNG TR·ªÑ (LATE DELIVERY PREDICTION)

## M·ª•c ti√™u b√†i to√°n
D·ª± ƒëo√°n `Late_delivery_risk` (0/1) d·ª±a tr√™n th√¥ng tin ƒë∆°n h√†ng, shipping, v√† th·ªùi ti·∫øt ƒë·ªÉ:
- C·∫£nh b√°o s·ªõm c√°c ƒë∆°n h√†ng c√≥ nguy c∆° giao tr·ªÖ
- T·ªëi ∆∞u h√≥a logistics v√† routing
- C·∫£i thi·ªán customer satisfaction

## Input (D·ªØ li·ªáu)
- **File ngu·ªìn:** `data/merged_supply_weather_clean.parquet`
- **S·ªë l∆∞·ª£ng:** ~180,000 records
- **C√°c nh√≥m feature:** Time, Shipping, Location, Product, Weather, Sales

## Output (Y√™u c·∫ßu d·ª± ƒëo√°n)
- **Target:** `Late_delivery_risk` (binary: 0 = on-time, 1 = late)
- **Output:** X√°c su·∫•t tr·ªÖ, label, v√† top features ·∫£nh h∆∞·ªüng

## Th√¥ng tin phi√™n b·∫£n
- **Ng√†y:** 2024
- **Phi√™n b·∫£n:** 1.0
- **Dataset:** merged_supply_weather_clean.parquet"""),
        
        # Import libraries
        create_notebook_cell("code", """# Import th∆∞ vi·ªán & c·∫•u h√¨nh chung
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, 
    roc_curve, f1_score, accuracy_score
)
import xgboost as xgb
import os
import warnings
warnings.filterwarnings('ignore')

# C·∫•u h√¨nh matplotlib
%matplotlib inline
plt.style.use('default')
sns.set_palette("husl")

# Random seed ƒë·ªÉ ƒë·∫£m b·∫£o reproducibility
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

print("‚úì ƒê√£ import th∆∞ vi·ªán v√† c·∫•u h√¨nh xong")"""),
        
        # Load data
        create_notebook_cell("markdown", """## 1. Load d·ªØ li·ªáu

Load d·ªØ li·ªáu merged ƒë√£ chu·∫©n h√≥a t·ª´ file `data/merged_supply_weather_clean.parquet`."""),
        
        create_notebook_cell("code", """# Load d·ªØ li·ªáu merged ƒë√£ chu·∫©n h√≥a
data_path = os.path.join('..', 'data', 'merged_supply_weather_clean.parquet')

if not os.path.exists(data_path):
    raise FileNotFoundError(f"File kh√¥ng t√¨m th·∫•y: {data_path}\\nVui l√≤ng ch·∫°y: python scripts/merge_supplychain_weather.py tr∆∞·ªõc")

df = pd.read_parquet(data_path)
print(f"‚úì ƒê√£ load {len(df):,} records")
print(f"‚úì S·ªë c·ªôt: {len(df.columns)}")

# Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n
print("\\n=== TH√îNG TIN DATASET ===")
df.info()

print("\\n=== 5 D√íNG ƒê·∫¶U TI√äN ===")
df.head()"""),
        
        # EDA
        create_notebook_cell("markdown", """## 2. EDA & Tr·ª±c quan h√≥a

Ph√¢n t√≠ch nhanh ph√¢n ph·ªëi target v√† m·ªëi t∆∞∆°ng quan gi·ªØa c√°c features quan tr·ªçng v·ªõi late delivery."""),
        
        create_notebook_cell("code", """# Ph√¢n ph·ªëi target
if 'Late_delivery_risk' not in df.columns:
    raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt target 'Late_delivery_risk'")

target_dist = df['Late_delivery_risk'].value_counts()
late_rate = df['Late_delivery_risk'].mean() * 100

print("=== PH√ÇN PH·ªêI TARGET ===")
print(target_dist)
print(f"\\nT·ªâ l·ªá giao tr·ªÖ: {late_rate:.2f}%")

# Visualize
plt.figure(figsize=(8, 5))
target_dist.plot(kind='bar', color=['green', 'red'])
plt.title('Ph√¢n ph·ªëi Late Delivery Risk', fontsize=14, fontweight='bold')
plt.xlabel('Late Delivery Risk (0=On-time, 1=Late)', fontsize=12)
plt.ylabel('S·ªë l∆∞·ª£ng', fontsize=12)
plt.xticks(rotation=0)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()"""),
        
        create_notebook_cell("code", """# T∆∞∆°ng quan gi·ªØa weather risk v√† late delivery
if 'weather_risk_level' in df.columns:
    weather_corr = df.groupby('weather_risk_level')['Late_delivery_risk'].mean()
    
    plt.figure(figsize=(10, 6))
    weather_corr.plot(kind='bar', color='coral')
    plt.title('T·ªâ l·ªá giao tr·ªÖ theo m·ª©c ƒë·ªô r·ªßi ro th·ªùi ti·∫øt', fontsize=14, fontweight='bold')
    plt.xlabel('Weather Risk Level (1-5)', fontsize=12)
    plt.ylabel('T·ªâ l·ªá giao tr·ªÖ', fontsize=12)
    plt.xticks(rotation=0)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    print("\\n=== T·ªà L·ªÜ GIAO TR·ªÑ THEO WEATHER RISK ===")
    print(weather_corr)"""),
        
        create_notebook_cell("code", """# Ph√¢n t√≠ch lead_time vs late delivery
if 'lead_time' in df.columns:
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Boxplot
    df.boxplot(column='lead_time', by='Late_delivery_risk', ax=axes[0])
    axes[0].set_title('Ph√¢n ph·ªëi Lead Time theo Late Delivery', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Late Delivery Risk', fontsize=11)
    axes[0].set_ylabel('Lead Time (ng√†y)', fontsize=11)
    plt.suptitle('')
    
    # Bar chart
    lead_time_avg = df.groupby('Late_delivery_risk')['lead_time'].mean()
    lead_time_avg.plot(kind='bar', color=['green', 'red'], ax=axes[1])
    axes[1].set_title('Lead Time trung b√¨nh theo Late Delivery', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('Late Delivery Risk', fontsize=11)
    axes[1].set_ylabel('Lead Time trung b√¨nh (ng√†y)', fontsize=11)
    axes[1].tick_params(axis='x', rotation=0)
    axes[1].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print("\\n=== LEAD TIME TRUNG B√åNH ===")
    print(lead_time_avg)"""),
        
        # Feature Engineering
        create_notebook_cell("markdown", """## 3. Ti·ªÅn x·ª≠ l√Ω & Feature Engineering

**Pipeline x·ª≠ l√Ω:**
- Ch·ªçn c√°c nh√≥m feature: Time, Shipping, Location, Product, Weather, Sales
- X·ª≠ l√Ω missing values: Fill median cho numeric, "Unknown" cho categorical
- Encoding: One-hot encoding cho categorical (gi·ªõi h·∫°n top 10 categories)
- Scaling: StandardScaler cho Logistic Regression (tree-based kh√¥ng c·∫ßn scale)"""),
        
        create_notebook_cell("code", """# Ch·ªçn c√°c nh√≥m feature
feature_groups = {
    'time_features': ['year', 'month', 'day_of_week', 'is_weekend', 'is_holiday_season', 
                      'month_sin', 'month_cos', 'day_of_week_sin', 'day_of_week_cos'],
    'shipping_features': ['Days for shipping (real)', 'Days for shipment (scheduled)', 
                          'lead_time', 'Shipping Mode'],
    'location_features': ['Order Country', 'Order City'],
    'product_features': ['Category Name', 'Order Item Quantity', 'Order Item Discount'],
    'weather_features': ['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_mean',
                        'relative_humidity_2m_mean', 'weather_risk_level'],
    'sales_features': ['Sales', 'Benefit per order']
}

# Thu th·∫≠p t·∫•t c·∫£ features c√≥ s·∫µn
all_features = []
for group, features in feature_groups.items():
    available = [f for f in features if f in df.columns]
    all_features.extend(available)
    print(f"‚úì {group}: {len(available)}/{len(features)} features")

print(f"\\nT·ªïng s·ªë features: {len(all_features)}")"""),
        
        create_notebook_cell("code", """# T√°ch X v√† y
X = df[all_features].copy()
y = df['Late_delivery_risk'].copy()

# X·ª≠ l√Ω missing values
X = X.fillna(X.median(numeric_only=True))
for col in X.select_dtypes(include=['object']).columns:
    X[col] = X[col].fillna('Unknown')

print(f"Feature matrix shape: {X.shape}")
print(f"S·ªë missing values c√≤n l·∫°i: {X.isnull().sum().sum()}")"""),
        
        create_notebook_cell("code", """# Encoding categorical variables
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()

print(f"S·ªë c·ªôt categorical: {len(categorical_cols)}")
print(f"S·ªë c·ªôt numeric: {len(numeric_cols)}")

# One-hot encoding (gi·ªõi h·∫°n top 10 categories ƒë·ªÉ tr√°nh qu√° nhi·ªÅu c·ªôt)
X_encoded = X[numeric_cols].copy()

for col in categorical_cols:
    top_cats = X[col].value_counts().head(10).index.tolist()
    for cat in top_cats:
        X_encoded[f'{col}_{cat}'] = (X[col] == cat).astype(int)
    X_encoded[f'{col}_Other'] = (~X[col].isin(top_cats)).astype(int)

print(f"\\nFeature matrix sau encoding: {X_encoded.shape}")"""),
        
        # Train/Test Split
        create_notebook_cell("markdown", """## 4. Chia t·∫≠p train/test

**Ti√™u ch√≠ chia:** Time-based split (80% train, 20% test) ƒë·ªÉ tr√°nh data leakage.
- Train: 80% d·ªØ li·ªáu ƒë·∫ßu ti√™n theo th·ªùi gian
- Test: 20% d·ªØ li·ªáu cu·ªëi c√πng"""),
        
        create_notebook_cell("code", """# Time-based split
if 'order date (DateOrders)' not in df.columns:
    raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt 'order date (DateOrders)'")

df_sorted = df.sort_values('order date (DateOrders)')
split_idx = int(len(df_sorted) * 0.8)

train_mask = df_sorted.index[:split_idx]
test_mask = df_sorted.index[split_idx:]

X_train = X_encoded.loc[train_mask]
X_test = X_encoded.loc[test_mask]
y_train = y.loc[train_mask]
y_test = y.loc[test_mask]

print(f"Train set: {len(X_train):,} samples")
print(f"Test set: {len(X_test):,} samples")
print(f"\\nTrain date range: {df_sorted.loc[train_mask, 'order date (DateOrders)'].min()} ƒë·∫øn {df_sorted.loc[train_mask, 'order date (DateOrders)'].max()}")
print(f"Test date range: {df_sorted.loc[test_mask, 'order date (DateOrders)'].min()} ƒë·∫øn {df_sorted.loc[test_mask, 'order date (DateOrders)'].max()}")"""),
        
        create_notebook_cell("code", """# Scaling features (ch·ªâ cho Logistic Regression, tree-based kh√¥ng c·∫ßn)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("‚úì ƒê√£ scale features cho Logistic Regression")"""),
        
        # Model Training
        create_notebook_cell("markdown", """## 5. Hu·∫•n luy·ªán m√¥ h√¨nh

**C√°c m√¥ h√¨nh s·∫Ω th·ª≠:**
- **Baseline:** Logistic Regression (ƒë∆°n gi·∫£n, d·ªÖ interpret)
- **Tree-based:** Random Forest, XGBoost (x·ª≠ l√Ω non-linear, feature importance)"""),
        
        create_notebook_cell("code", """# 5.1. Logistic Regression (Baseline)
lr_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced')
lr_model.fit(X_train_scaled, y_train)

y_pred_lr = lr_model.predict(X_test_scaled)
y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]

print("=== K·∫æT QU·∫¢ LOGISTIC REGRESSION ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred_lr):.4f}")
print(f"AUC-ROC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}")
print("\\nClassification Report:")
print(classification_report(y_test, y_pred_lr))"""),
        
        create_notebook_cell("code", """# 5.2. Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=RANDOM_STATE,
    class_weight='balanced',
    n_jobs=-1
)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

print("=== K·∫æT QU·∫¢ RANDOM FOREST ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred_rf):.4f}")
print(f"AUC-ROC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}")
print("\\nClassification Report:")
print(classification_report(y_test, y_pred_rf))"""),
        
        create_notebook_cell("code", """# 5.3. XGBoost
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum() if y_train.sum() > 0 else 1

xgb_model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=RANDOM_STATE,
    scale_pos_weight=scale_pos_weight
)
xgb_model.fit(X_train, y_train)

y_pred_xgb = xgb_model.predict(X_test)
y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

print("=== K·∫æT QU·∫¢ XGBOOST ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")
print(f"F1 Score: {f1_score(y_test, y_pred_xgb):.4f}")
print(f"AUC-ROC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}")
print("\\nClassification Report:")
print(classification_report(y_test, y_pred_xgb))"""),
        
        # Evaluation
        create_notebook_cell("markdown", """## 6. ƒê√°nh gi√° m√¥ h√¨nh & Tr·ª±c quan h√≥a

**Metrics ch√≠nh:**
- **Accuracy:** T·ªâ l·ªá d·ª± ƒëo√°n ƒë√∫ng
- **F1 Score:** Harmonic mean c·ªßa Precision v√† Recall (quan tr·ªçng v·ªõi class imbalance)
- **AUC-ROC:** Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng ROC (ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n lo·∫°i)"""),
        
        create_notebook_cell("code", """# So s√°nh c√°c m√¥ h√¨nh
models_dict = {
    'Logistic Regression': (y_pred_proba_lr, y_pred_lr),
    'Random Forest': (y_pred_proba_rf, y_pred_rf),
    'XGBoost': (y_pred_proba_xgb, y_pred_xgb)
}

results = []
for name, (proba, pred) in models_dict.items():
    results.append({
        'Model': name,
        'Accuracy': accuracy_score(y_test, pred),
        'F1': f1_score(y_test, pred),
        'AUC-ROC': roc_auc_score(y_test, proba)
    })

results_df = pd.DataFrame(results)
print("\\n=== SO S√ÅNH C√ÅC M√î H√åNH ===")
print(results_df.to_string(index=False))"""),
        
        create_notebook_cell("code", """# ROC Curves
plt.figure(figsize=(10, 8))

for name, (proba, _) in models_dict.items():
    fpr, tpr, _ = roc_curve(y_test, proba)
    auc = roc_auc_score(y_test, proba)
    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'k--', label='Random', linestyle='--')
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curves - So s√°nh c√°c m√¥ h√¨nh', fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()"""),
        
        create_notebook_cell("code", """# Confusion Matrices
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

for idx, (name, (_, pred)) in enumerate(models_dict.items()):
    cm = confusion_matrix(y_test, pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], cbar_kws={'label': 'Count'})
    axes[idx].set_title(f'{name}\\nAccuracy: {accuracy_score(y_test, pred):.3f}', fontsize=12, fontweight='bold')
    axes[idx].set_xlabel('Predicted', fontsize=11)
    axes[idx].set_ylabel('Actual', fontsize=11)

plt.tight_layout()
plt.show()"""),
        
        create_notebook_cell("code", """# Feature Importance (XGBoost)
if hasattr(xgb_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': xgb_model.feature_importances_
    }).sort_values('importance', ascending=False).head(20)
    
    plt.figure(figsize=(10, 8))
    sns.barplot(data=feature_importance, y='feature', x='importance', palette='viridis')
    plt.title('Top 20 Feature Importances (XGBoost)', fontsize=14, fontweight='bold')
    plt.xlabel('Importance', fontsize=12)
    plt.ylabel('Feature', fontsize=12)
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    print("\\n=== TOP 10 FEATURES QUAN TR·ªåNG NH·∫§T ===")
    print(feature_importance.head(10).to_string(index=False))"""),
        
        # Conclusion
        create_notebook_cell("markdown", """## 7. K·∫øt lu·∫≠n & G·ª£i √Ω

### K·∫øt qu·∫£ ch√≠nh
- **Model t·ªët nh·∫•t:** XGBoost (d·ª±a tr√™n AUC-ROC v√† F1 Score)
- **Metric ch√≠nh:** AUC-ROC v√† F1 Score (quan tr·ªçng v·ªõi class imbalance)

### Nh·∫≠n x√©t
**Features quan tr·ªçng (d·ª±a tr√™n feature importance):**
- `lead_time`: Ch√™nh l·ªách th·ªùi gian giao h√†ng l√† y·∫øu t·ªë quan tr·ªçng nh·∫•t
- `weather_risk_level`: Th·ªùi ti·∫øt kh·∫Øc nghi·ªát l√†m tƒÉng nguy c∆° tr·ªÖ
- `Days for shipping (real)`: Th·ªùi gian giao h√†ng th·ª±c t·∫ø
- Time features (weekend, holiday season) c√≥ ·∫£nh h∆∞·ªüng ƒë·∫øn logistics

### H·∫°n ch·∫ø
- ‚ö†Ô∏è Class imbalance c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn performance
- ‚ö†Ô∏è Thi·∫øu m·ªôt s·ªë features (v√≠ d·ª•: traffic conditions, road quality, distance ch√≠nh x√°c)
- ‚ö†Ô∏è Model ch∆∞a ƒë∆∞·ª£c hyperparameter tuning k·ªπ
- ‚ö†Ô∏è Ch∆∞a c√≥ validation tr√™n d·ªØ li·ªáu m·ªõi nh·∫•t (out-of-time validation)

### H∆∞·ªõng ph√°t tri·ªÉn
1. **Feature Engineering:**
   - Rolling statistics (7-day, 30-day averages c·ªßa s·ªë ƒë∆°n tr·ªÖ)
   - Lag features (s·ªë ƒë∆°n tr·ªÖ trong 7 ng√†y tr∆∞·ªõc)
   - Distance features (kho·∫£ng c√°ch t·ª´ warehouse ƒë·∫øn customer)

2. **Model Improvement:**
   - Hyperparameter tuning (GridSearchCV/RandomSearchCV)
   - Ensemble methods (voting, stacking)
   - Deep Learning (n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu)

3. **Deployment:**
   - Real-time prediction API
   - Model monitoring (drift detection)
   - A/B testing""")
    ]
    
    notebook = {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.8.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return notebook

def main():
    """Generate c√°c notebook chu·∫©n h√≥a."""
    notebooks_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'notebooks')
    os.makedirs(notebooks_dir, exist_ok=True)
    
    # Generate Late Delivery notebook
    print("Generating model_late_delivery.ipynb...")
    notebook = create_late_delivery_notebook()
    output_path = os.path.join(notebooks_dir, 'model_late_delivery.ipynb')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, indent=2, ensure_ascii=False)
    print(f"‚úì Created: {output_path}")
    
    print("\n‚úÖ Ho√†n th√†nh! Notebook ƒë√£ ƒë∆∞·ª£c t·∫°o theo layout chu·∫©n.")
    print("üìù L∆∞u √Ω: C√°c notebook kh√°c (revenue_forecast, customer_churn) s·∫Ω ƒë∆∞·ª£c t·∫°o t∆∞∆°ng t·ª±.")

if __name__ == '__main__':
    main()

